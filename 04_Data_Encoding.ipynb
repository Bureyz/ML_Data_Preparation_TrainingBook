{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b598931-5bf2-486d-b151-aff046b65dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks Data Preparation in ML - Notebook 04\n",
    "## Data Encoding Fundamentals\n",
    "\n",
    "**Part of the Databricks Data Preparation in ML Training Series**\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "This notebook covers essential categorical variable encoding techniques required for Databricks ML Associate Certification:\n",
    "\n",
    "- **Label Encoding** - Simple numerical mapping for ordinal categories\n",
    "- **One-Hot Encoding** - Binary vectors for nominal categories  \n",
    "- **Ordinal Encoding** - Preserving natural ordering in categorical data\n",
    "- **Target Encoding** - Leveraging target variable information\n",
    "- **Categorical Embeddings** - Learned representations through deep learning\n",
    "- **Text Embeddings** - Semantic encoding for textual data\n",
    "\n",
    "## Duration: ~45 minutes\n",
    "## Level: Fundamental → Advanced\n",
    "\n",
    "---\n",
    "\n",
    "## Why is Categorical Encoding Critical?\n",
    "\n",
    "ML algorithms work with **numerical data**, but business data contains **categorical text information**:\n",
    "- Cities, products, customer segments\n",
    "- Status values, ratings, sizes\n",
    "- Textual descriptions, comments, reviews\n",
    "\n",
    "**Proper encoding** can dramatically improve ML model performance and training efficiency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eda52282-0ce3-4925-a9c6-38377e2b5a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Theory: Categorical Types and Encoding Methods\n",
    "\n",
    "### Types of Categorical Variables\n",
    "\n",
    "Understanding the nature of categorical data is crucial for selecting the appropriate encoding strategy.\n",
    "\n",
    "#### **Nominal Categories** (No natural ordering)\n",
    "- Cities: \"Warsaw\", \"Krakow\", \"Gdansk\"\n",
    "- Colors: \"red\", \"blue\", \"green\"  \n",
    "- Brands: \"Apple\", \"Samsung\", \"Google\"\n",
    "- **Characteristic**: Categories are mutually exclusive with no inherent ranking\n",
    "\n",
    "#### **Ordinal Categories** (Natural hierarchy exists)\n",
    "- Education: elementary < high school < bachelor < master < PhD\n",
    "- Sizes: XS < S < M < L < XL\n",
    "- Ratings: poor < fair < good < excellent\n",
    "- **Characteristic**: Categories have meaningful order relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10faf3c6-9392-42dc-bed5-6c74ebcb1754",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7148149-d325-46bb-96ff-b73b37563035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Basic imports for Databricks ML\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, avg, count, when, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37bb927f-edb9-48f4-9e46-0331ec20ee17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49c7d7d4-b075-4c9b-a393-afbb72e2e0a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Zakres danych\n",
    "n_rows = 1000\n",
    "\n",
    "education_levels = [\"elementary\", \"high_school\", \"bachelor\", \"master\", \"phd\"]\n",
    "cities = [\"London\", \"Manchester\", \"Birmingham\", \"Leeds\", \"Glasgow\"]\n",
    "departments = [\"IT\", \"Marketing\", \"Finance\", \"HR\", \"Operations\"]\n",
    "performance_levels = [\"poor\", \"average\", \"good\", \"excellent\"]\n",
    "\n",
    "def random_salary(edu, perf):\n",
    "    base = {\n",
    "        \"elementary\": 3000,\n",
    "        \"high_school\": 4000,\n",
    "        \"bachelor\": 6000,\n",
    "        \"master\": 8000,\n",
    "        \"phd\": 10000\n",
    "    }.get(edu, 5000)\n",
    "    bonus = {\n",
    "        \"poor\": -1000,\n",
    "        \"average\": 0,\n",
    "        \"good\": 1000,\n",
    "        \"excellent\": 2000\n",
    "    }.get(perf, 0)\n",
    "    return float(base + bonus + random.randint(-500, 500))\n",
    "\n",
    "data = []\n",
    "for i in range(1, n_rows + 1):\n",
    "    edu = random.choice(education_levels)\n",
    "    city = random.choice(cities)\n",
    "    dept = random.choice(departments)\n",
    "    perf = random.choice(performance_levels)\n",
    "    salary = random_salary(edu, perf)\n",
    "    description = fake.sentence(nb_words=8) + \" \" + fake.job()\n",
    "    data.append((i, edu, city, dept, perf, salary, description))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"education\", StringType(), True),       # ORDINAL\n",
    "    StructField(\"city\", StringType(), True),            # NOMINAL  \n",
    "    StructField(\"department\", StringType(), True),      # NOMINAL\n",
    "    StructField(\"performance\", StringType(), True),     # ORDINAL\n",
    "    StructField(\"salary\", DoubleType(), True),          # TARGET\n",
    "    StructField(\"description\", StringType(), True)      # TEXT\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae22f1c4-0899-4c99-8577-6881261d0342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Label Encoding - Mapping to numbers\n",
    "\n",
    "## Theory\n",
    "**Label Encoding** assigns each category a unique integer (0, 1, 2, 3...).\n",
    "\n",
    "### ✅ When to use:\n",
    "- **Ordinal** data with natural ordering  \n",
    "- **Tree-based models** (Random Forest, XGBoost)\n",
    "- Need **compact representation**\n",
    "\n",
    "### ❌ When to avoid:\n",
    "- **Nominal** data without ordering (artificial ranking!)\n",
    "- **Linear models** (interpret numbers as order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20520268-9944-4b17-b676-c2fa63acc71a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Label Encoding for education (ordinal)\n",
    "education_indexer = StringIndexer(\n",
    "    inputCol=\"education\", \n",
    "    outputCol=\"education_encoded\"\n",
    ")\n",
    "\n",
    "education_model = education_indexer.fit(df)\n",
    "df_label = education_model.transform(df)\n",
    "\n",
    "# Check mapping\n",
    "df_label.select(\"education\", \"education_encoded\").distinct().orderBy(\"education_encoded\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cd1fa33-9ff0-4d46-8c6b-3f6cfba2dae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ⚠️ WARNING: StringIndexer codes by frequency, not logically!\n",
    "# For ordinal data it's better to use manual mapping:\n",
    "\n",
    "education_order = {\"elementary\": 1, \"high_school\": 2, \"bachelor\": 3, \"master\": 4}\n",
    "df_manual = df.withColumn(\"education_manual\", \n",
    "    when(col(\"education\") == \"elementary\", 1)\n",
    "    .when(col(\"education\") == \"high_school\", 2)  \n",
    "    .when(col(\"education\") == \"bachelor\", 3)\n",
    "    .when(col(\"education\") == \"master\", 4)\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "df_manual.select(\"education\", \"education_manual\").distinct().orderBy(\"education_manual\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af4a7cf-1b21-4a08-8fc4-90eb75af23c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#One-Hot Encoding - Binary vectors\n",
    "\n",
    "## Theory\n",
    "**One-Hot Encoding** creates **separate binary column (0/1)** for each unique category.\n",
    "\n",
    "###  When to use:\n",
    "- **Nominal** data without natural ordering\n",
    "- **Linear models** (Logistic Regression, SVM)  \n",
    "- **Low cardinality** (<20 categories)\n",
    "\n",
    "###  When to avoid:\n",
    "- **High cardinality** (>20 categories) → curse of dimensionality\n",
    "- **Limited memory** → many sparse columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd50b91-3c09-44b0-8169-f147a63f6311",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"dept_onehot\":669},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1753552967383}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding for department (nominal)\n",
    "# Step 1: StringIndexer (required before OneHotEncoder)\n",
    "dept_indexer = StringIndexer(inputCol=\"department\", outputCol=\"dept_indexed\")\n",
    "df_indexed = dept_indexer.fit(df_label).transform(df_label)\n",
    "\n",
    "# Step 2: OneHotEncoder  \n",
    "dept_encoder = OneHotEncoder(\n",
    "    inputCols=[\"dept_indexed\"], \n",
    "    outputCols=[\"dept_onehot\"],\n",
    "   # dropLast=False\n",
    ")\n",
    "df_onehot = dept_encoder.fit(df_indexed).transform(df_indexed)\n",
    "\n",
    "# Check results\n",
    "df_onehot.select(\"department\", \"dept_indexed\", \"dept_onehot\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94ffc19f-0716-48fb-a82f-7bc1ff4194c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analysis of One-Hot Encoding dimensions\n",
    "unique_depts = df.select(\"department\").distinct().count()\n",
    "sample_vector = df_onehot.select(\"dept_onehot\").first()[\"dept_onehot\"]\n",
    "\n",
    "print(f\"Categories: {unique_depts}\")\n",
    "print(f\"Vector dimensions: {len(sample_vector)}\")\n",
    "print(f\"Sample vector: {sample_vector.toArray()}\")\n",
    "\n",
    "# \uD83D\uDCA1 Each category = 1 column, others = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d11ddd53-d5e2-4999-84ba-33dd213d04e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Ordinal Encoding - Preserving Order\n",
    "\n",
    "## Theory  \n",
    "**Ordinal Encoding** is **manual mapping** of ordinal categories to numbers, preserving natural hierarchy.\n",
    "\n",
    "###  When to use:\n",
    "- Data with **clear ordering** (sizes, ratings, levels)\n",
    "- You need to **preserve relationships** between categories\n",
    "- **All ML model types**\n",
    "\n",
    "###  Advantages vs Label Encoding:\n",
    "- **Control** over mapping  \n",
    "- **Logical order** vs frequency occurrence\n",
    "- **Consistent** results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3978c868-fdc8-4fc8-afdf-8d3fa495af67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "df_ordinalEncoder = pd.DataFrame({\n",
    "    \"education\": [\"elementary\", \"bachelor\", \"high_school\", \"master\", \"phd\"]\n",
    "})\n",
    "\n",
    "# Ręczna definicja porządku (dla danych ordinalnych)\n",
    "encoder = OrdinalEncoder(categories=[[\"elementary\", \"high_school\", \"bachelor\", \"master\", \"phd\"]])\n",
    "df_ordinalEncoder[\"education_index\"] = encoder.fit_transform(df[[\"education\"]])\n",
    "\n",
    "display(df_ordinalEncoder.sort_values(\"education_index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd8948f4-4da7-4ab9-8c81-e3facca2640a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ordinal Encoding for performance (ordinal with clear ordering)\n",
    "df_ordinal = df_onehot.withColumn(\"performance_ordinal\",\n",
    "    when(col(\"performance\") == \"poor\", 1)\n",
    "    .when(col(\"performance\") == \"average\", 2)\n",
    "    .when(col(\"performance\") == \"good\", 3) \n",
    "    .when(col(\"performance\") == \"excellent\", 4)\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Check mapping\n",
    "df_ordinal.select(\"performance\", \"performance_ordinal\").distinct().orderBy(\"performance_ordinal\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d27853d5-a84e-439a-b421-c684c19751aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Comparison: Ordinal vs StringIndexer\n",
    "perf_indexer = StringIndexer(inputCol=\"performance\", outputCol=\"performance_auto\")\n",
    "df_comparison = perf_indexer.fit(df_ordinal).transform(df_ordinal)\n",
    "\n",
    "df_comparison.select(\"performance\", \"performance_ordinal\", \"performance_auto\").distinct().orderBy(\"performance_ordinal\").display()\n",
    "\n",
    "# \uD83D\uDCA1 Ordinal preserves logical order, StringIndexer codes by frequency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c823ee39-e7c6-4c97-97ba-bfcd2b0484e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Target Encoding - Information from target variable\n",
    "\n",
    "## Theory\n",
    "**Target Encoding** replaces each category with **target variable statistics** (e.g. mean, median).\n",
    "\n",
    "###  When to use:\n",
    "- **High cardinality** (>20-50 categories)\n",
    "- **Tree-based models** (Random Forest, XGBoost)\n",
    "- Categories with **different predictive power**\n",
    "\n",
    "###  WARNINGS:\n",
    "- **Overfitting risk** - use cross-validation!\n",
    "- **Data leakage** - don't use target info from validation/test\n",
    "- **Smoothing** for small samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a1e775f-39cc-41de-a7bb-a654658f1c3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Target Encoding for city (average salary per city)\n",
    "city_target_stats = df.groupBy(\"city\").agg(\n",
    "    avg(\"salary\").alias(\"city_avg_salary\"),\n",
    "    count(\"*\").alias(\"city_count\")\n",
    ")\n",
    "\n",
    "city_target_stats.orderBy(\"city_avg_salary\", ascending=False).display()\n",
    "\n",
    "# Join with main dataset\n",
    "df_target = df_comparison.join(city_target_stats, \"city\")\n",
    "df_target.select(\"city\", \"salary\", \"city_avg_salary\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aacd4e0-e8c6-4f8a-bd2e-9827836d4489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian Smoothing for small samples\n",
    "global_mean = df.agg(avg(\"salary\")).collect()[0][0]\n",
    "alpha = 3  # smoothing parameter\n",
    "\n",
    "df_smoothed = city_target_stats.withColumn(\"city_smoothed_salary\",\n",
    "    (col(\"city_count\") * col(\"city_avg_salary\") + lit(alpha) * lit(global_mean)) / \n",
    "    (col(\"city_count\") + lit(alpha))\n",
    ")\n",
    "\n",
    "df_smoothed.select(\"city\", \"city_count\", \"city_avg_salary\", \"city_smoothed_salary\").display()\n",
    "\n",
    "# \uD83D\uDCA1 Smoothing \"shrinks\" small samples toward global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c373e70-34ce-4d9a-a51f-efb9554fa14f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "city_target_stats.createOrReplaceTempView(\"city_target_stats\")\n",
    "\n",
    "global_mean = df.agg(avg(\"salary\")).collect()[0][0]\n",
    "alpha = 3\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "  city,\n",
    "  city_count,\n",
    "  city_avg_salary,\n",
    "  (city_count * city_avg_salary + {alpha} * {global_mean}) / (city_count + {alpha}) AS city_smoothed_salary\n",
    "FROM city_target_stats\n",
    "\"\"\"\n",
    "\n",
    "df_smoothed_sql = spark.sql(query)\n",
    "display(df_smoothed_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "184c2918-f565-4803-ba2f-faed385562b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Categorical Embeddings - VectorAssembler\n",
    "\n",
    "## Theory\n",
    "**Categorical Embeddings** are **learned dense vector representations** of categories, trained end-to-end with neural network models.\n",
    "\n",
    "###  When to use:\n",
    "- **High cardinality** (>50-100 categories)\n",
    "- **Deep learning models** (neural networks)\n",
    "- **Complex relationships** between categories\n",
    "- **Recommendation systems**\n",
    "\n",
    "###  Advantages:\n",
    "- **Automatic similarity learning** - similar categories → similar vectors\n",
    "- **Dense representation** vs sparse one-hot\n",
    "- **Tunable dimensions** - control over size\n",
    "\n",
    "### Embedding dimensions (rule of thumb):\n",
    "```python\n",
    "embedding_dim = min(50, (cardinality + 1) // 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae69541b-bdf5-408b-a801-d1de0edd3943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0edb1173-4ec8-4df6-b741-fcd6f8575a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "\n",
    "# 1. Encode the 'department' column into numerical indices\n",
    "indexer = StringIndexer(inputCol=\"department\", outputCol=\"department_idx\")\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "\n",
    "# 2. Select features for vectorization\n",
    "# Example: we use 'department_idx' and 'salary' as input features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"department_idx\", \"salary\"],  # you can add other numerical features here\n",
    "    outputCol=\"features_vector\"\n",
    ")\n",
    "\n",
    "df_vectorized = assembler.transform(df_indexed)\n",
    "\n",
    "# 3. Check the result\n",
    "df_vectorized.select(\"department\", \"department_idx\", \"salary\", \"features_vector\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02cb6c8f-7b6e-4e5f-83d9-322e359b89bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Text Embeddings - Semantic encoding\n",
    "\n",
    "## Theory\n",
    "**Text Embeddings** transform **text into dense vector representations** that capture semantic meaning.\n",
    "\n",
    "### When to use:\n",
    "- **Text features** (descriptions, reviews, documents)\n",
    "- **Semantic search** and similarity matching\n",
    "- **Document classification** and clustering\n",
    "- **Multilingual** applications\n",
    "\n",
    "### Popular models:\n",
    "\n",
    "| Model | Provider | Dimensions | Best for |\n",
    "|-------|----------|---------|---------------|\n",
    "| **all-MiniLM-L6-v2** | Sentence-BERT | 384 | Fast, local |\n",
    "| **text-embedding-ada-002** | OpenAI | 1536 | High quality |\n",
    "| **all-mpnet-base-v2** | Sentence-BERT | 768 | Balanced |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f21affe-b0b7-4db1-82f3-b3baac971d75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Konwersja do Pandas\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Załaduj model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generuj embeddingi\n",
    "pdf[\"embedding\"] = model.encode(pdf[\"description\"].tolist()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d8121b-5e17-4544-b523-66ec26807f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "\n",
    "# Dodaj kolumnę z embeddingiem do Spark DF\n",
    "pdf[\"embedding\"] = pdf[\"embedding\"].apply(lambda x: [float(i) for i in x])\n",
    "df_embedded = spark.createDataFrame(pdf)\n",
    "\n",
    "display(df_embedded.select(\"id\", \"description\", \"embedding\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e614c14-2b82-4bd4-8f11-ca6b34c098e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#  Summary: Choosing the Right Encoding Method\n",
    "\n",
    "##  Decision Matrix - ML Associate Certification\n",
    "\n",
    "| Scenario | Cardinality | Category Type | ML Algorithm | **Recommended Method** |\n",
    "|----------|-------------|---------------|-------------|----------------------|\n",
    "| Colors, countries | Low (2-10) | Nominal | Linear/SVM | **One-Hot** |\n",
    "| Education level | Low | Ordinal | All | **Ordinal** (manual) |\n",
    "| User IDs | High (1000+) | Nominal | Tree-based | **Target Encoding** |\n",
    "| Product codes | High | Nominal | Neural Network | **Embeddings** |\n",
    "| Descriptions | Text | Semantic | All | **Text Embeddings** |\n",
    "| Ratings (1-5) | Low | Ordinal | All | **Keep numeric** |\n",
    "\n",
    "##  Common Mistakes - ML Associate\n",
    "\n",
    "1. **Label encoding for nominal** → artificial ordering\n",
    "2. **One-hot for high cardinality** → curse of dimensionality  \n",
    "3. **Target encoding without CV** → data leakage\n",
    "4. **Inconsistent train/test encoding** → model degradation\n",
    "\n",
    "##  Production Best Practices\n",
    "\n",
    "###  Pipeline Design\n",
    "- **Consistent encoding** across train/validation/test\n",
    "- **Handle unknown categories** (StringIndexer handleInvalid=\"keep\")\n",
    "- **Version control** for encoding mappings\n",
    "- **Monitoring** for distribution drift\n",
    "\n",
    "###  Performance Tips\n",
    "- **Batch processing** for embeddings API calls\n",
    "- **Caching** for expensive operations  \n",
    "- **Sparse formats** for one-hot (memory efficiency)\n",
    "- **Pipeline optimization** (avoid repeated transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73797ada-c7b1-412e-88bb-149ee905a9f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8698289734080766,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Data_Encoding",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}